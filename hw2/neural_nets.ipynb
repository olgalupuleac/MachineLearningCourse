{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mnist = pd.read_csv('mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "num_epochs = 5 \n",
    "num_classes = 10 \n",
    "batch_size = 25\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "\n",
    "def create_dataset(df):\n",
    "    X = df.drop('label', axis=1)\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    dataset = [[np.array([X[i].reshape(28, 28)]), df['label'].values[i]] for i in range(len(X))]\n",
    "    del X\n",
    "    gc.collect()\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olga\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\olga\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "train_mnist, test_mnist = train_test_split(mnist)\n",
    "\n",
    "train_loader = create_dataset(train_mnist)\n",
    "test_loader = create_dataset(test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "import numpy as np\n",
    "\n",
    "class ConvNet(nn.Module): \n",
    "    def __init__(self, activation_function): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1), \n",
    "                                    activation_function) \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1), \n",
    "                                    activation_function)\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1), \n",
    "                                    activation_function)\n",
    "        self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(8 * 28 * 28, 64) \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out) \n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1) \n",
    "        out = self.drop_out(out) \n",
    "        out = self.fc1(out) \n",
    "        out = self.fc2(out) \n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    total_step = len(train_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            outputs = model(images.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, loss.item(),\n",
    "                              (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the {} test images: {} %'.format(total, (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.4000, Accuracy: 88.00%\n",
      "Epoch [2/5], Loss: 0.1128, Accuracy: 92.00%\n",
      "Epoch [3/5], Loss: 0.0262, Accuracy: 100.00%\n",
      "Epoch [4/5], Loss: 0.3104, Accuracy: 88.00%\n",
      "Epoch [5/5], Loss: 0.1708, Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "digits_relu_model = ConvNet(nn.ReLU())\n",
    "train(digits_relu_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 2500 test images: 96.12 %\n"
     ]
    }
   ],
   "source": [
    "test(digits_relu_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.3071, Accuracy: 8.00%\n",
      "Epoch [2/5], Loss: 2.2732, Accuracy: 12.00%\n",
      "Epoch [3/5], Loss: 0.7781, Accuracy: 80.00%\n",
      "Epoch [4/5], Loss: 0.4369, Accuracy: 88.00%\n",
      "Epoch [5/5], Loss: 0.1824, Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "digits_sigmoid_model = ConvNet(nn.Sigmoid())\n",
    "train(digits_sigmoid_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 2500 test images: 87.56 %\n"
     ]
    }
   ],
   "source": [
    "test(digits_sigmoid_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.5852, Accuracy: 88.00%\n",
      "Epoch [2/5], Loss: 0.5344, Accuracy: 76.00%\n",
      "Epoch [3/5], Loss: 0.2770, Accuracy: 88.00%\n",
      "Epoch [4/5], Loss: 0.6808, Accuracy: 92.00%\n",
      "Epoch [5/5], Loss: 0.1165, Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "digits_tahn_model = ConvNet(nn.Tanh())\n",
    "train(digits_tahn_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 2500 test images: 89.92 %\n"
     ]
    }
   ],
   "source": [
    "test(digits_tahn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "images = []\n",
    "str_labels = 'ABCDEFGHIJ'\n",
    "path = 'notMNIST_small'\n",
    "for cur_dir, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        img = cv2.imread(os.path.join(cur_dir, file), 0)\n",
    "        if img is None:\n",
    "            continue\n",
    "        label = str_labels.find(cur_dir[-1])\n",
    "        assert label != -1\n",
    "        images.append([np.array([img]), label])\n",
    "random.shuffle(images)\n",
    "letters_train_loader = DataLoader(dataset=images[:int(len(images) * 0.8)], batch_size=batch_size, shuffle=True) \n",
    "letters_test_loader = DataLoader(dataset=images[int(len(images) * 0.8):], batch_size=batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2802, Accuracy: 100.00%\n",
      "Epoch [2/5], Loss: 0.0195, Accuracy: 100.00%\n",
      "Epoch [3/5], Loss: 0.2244, Accuracy: 100.00%\n",
      "Epoch [4/5], Loss: 0.0303, Accuracy: 100.00%\n",
      "Epoch [5/5], Loss: 0.0535, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "letters_relu_model = ConvNet(nn.ReLU())\n",
    "train(letters_relu_model, letters_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 3745 test images: 92.41655540720961 %\n"
     ]
    }
   ],
   "source": [
    "test(letters_relu_model, letters_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0627, Accuracy: 100.00%\n",
      "Epoch [2/5], Loss: 0.4120, Accuracy: 75.00%\n",
      "Epoch [3/5], Loss: 0.0308, Accuracy: 100.00%\n",
      "Epoch [4/5], Loss: 1.3915, Accuracy: 75.00%\n",
      "Epoch [5/5], Loss: 0.7033, Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "letters_sigmoid_model = ConvNet(nn.Sigmoid())\n",
    "train(letters_sigmoid_model, letters_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 3745 test images: 90.41388518024031 %\n"
     ]
    }
   ],
   "source": [
    "test(letters_sigmoid_model, letters_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0106, Accuracy: 100.00%\n",
      "Epoch [2/5], Loss: 0.0791, Accuracy: 100.00%\n",
      "Epoch [3/5], Loss: 0.0204, Accuracy: 100.00%\n",
      "Epoch [4/5], Loss: 1.2357, Accuracy: 75.00%\n",
      "Epoch [5/5], Loss: 1.6758, Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "letters_tahn_model = ConvNet(nn.Tanh())\n",
    "train(letters_tahn_model, letters_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 3745 test images: 92.22963951935914 %\n"
     ]
    }
   ],
   "source": [
    "test(letters_tahn_model, letters_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
